{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef5822ea",
   "metadata": {},
   "source": [
    "Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f4b22d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import mne\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "from loguru import logger\n",
    "# from DataCollection.actions import Action\n",
    "from scipy import stats\n",
    "from scipy import signal\n",
    "from scipy import integrate\n",
    "from sklearn.decomposition import PCA\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f66741ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.use(\"TkAgg\")  # TkAgg is a backend that uses the Tkinter GUI toolkit for rendering interactive plots in a separate interactive window, where you can zoom, pan, or save the plot.\n",
    "EPSILON = 1e-8  # constant EPSILON is a very small positive number, to avoid Division by Zero, and prevent Logarithmic Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fe4732",
   "metadata": {},
   "source": [
    "Define the `Action` data class, which encapsulates information about user actions in the EEG dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8a96e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Action:\n",
    "    action_value: int\n",
    "    text: str\n",
    "    audio: str\n",
    "    image: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7860a8b8",
   "metadata": {},
   "source": [
    "Visualization utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67cf0c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFT Plotting\n",
    "def plot_fft(data, sampling_frequency, fft_window_size, percent_overlap_between_windows):\n",
    "    pxx, freqs, bins, im = plt.specgram(\n",
    "        data,\n",
    "        Fs=sampling_frequency,\n",
    "        NFFT=fft_window_size,\n",
    "        noverlap=int(percent_overlap_between_windows * fft_window_size),\n",
    "    )\n",
    "    plt.colorbar(label=\"Power/Frequency (dB/Hz)\")\n",
    "    plt.title(\"FFT Spectrogram\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Frequency (Hz)\")\n",
    "    plt.show()\n",
    "    print(f\"Spectrogram shape: {pxx.shape}, Frequency bins: {freqs.shape}, Time bins: {bins.shape}\")\n",
    "    return pxx, freqs, bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17c66c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entropy Calculation\n",
    "def plot_entropy_of_data_time_and_frequency_dimensions(pxx, freqs, times):\n",
    "    frame_entropies = np.apply_along_axis(lambda x: stats.entropy(x + EPSILON), 0, pxx)\n",
    "    freq_entropies = np.apply_along_axis(lambda x: stats.entropy(x + EPSILON), 1, pxx)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(freqs, freq_entropies, label=\"Frequency Band Entropy\")\n",
    "    plt.xlabel(\"Frequency (Hz)\")\n",
    "    plt.ylabel(\"Entropy\")\n",
    "    plt.title(\"Entropy Across Frequencies\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(times, frame_entropies, label=\"Time Frame Entropy\", color=\"orange\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Entropy\")\n",
    "    plt.title(\"Entropy Across Time Frames\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e80603",
   "metadata": {},
   "source": [
    "Load Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11032d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNR Calculation\n",
    "def snr(signal):\n",
    "    signal_power = np.mean(signal**2)\n",
    "    noise = signal - np.mean(signal)\n",
    "    noise_power = np.mean(noise**2)\n",
    "    return 10 * np.log10(signal_power / noise_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ed722a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_timestamp_to_time_since_last_epoch(df):\n",
    "    \"\"\"Converts the timestamp to time since the last epoch.\"\"\"\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"]).astype(int) / 10**9\n",
    "    #Converts the timestamp column to pandas datetime format\n",
    "    #a column of datetime64[ns] objects as the number of nanoseconds since the Unix epoch (January 1, 1970, 00:00:00 UTC).\n",
    "    #Then convert the datetime64[ns] type to int, it returns the raw nanoseconds since the epoch.\n",
    "    #Dividing by 10**9 (1 billion) converts the nanosecond-based timestamp into seconds.\n",
    "    return df\n",
    "\n",
    "def align_data_to_experiment_start_and_end_time(df, start_time: float, end_time: float):\n",
    "    \"\"\"Aligns the data to the experiment start and end time.\"\"\"\n",
    "    #Ensures that the end_time is greater than the start_time before proceeding.\n",
    "    #If this condition is not true, the program will raise an AssertionError and stop execution.\n",
    "    assert end_time > start_time\n",
    "    #Selects rows where the timestamp value is greater than or equal to start_time\n",
    "    #Selects rows where the timestamp value is less than or equal to end_time\n",
    "    #The & operator performs an element-wise logical \"AND\". \n",
    "    #Only rows that satisfy both conditions will be included.\n",
    "    #Returns a new DataFrame with only the rows that satisfy the time range condition\n",
    "    return df[(df[\"timestamp\"] >= start_time) & (df[\"timestamp\"] <= end_time)]\n",
    "\n",
    "def time_align_accel_data_by_linearly_interpolating(accel_data, eeg_data):\n",
    "    \"\"\"Aligns accelerometer data with EEG data using linear interpolation.\"\"\"\n",
    "    #align accel_data to match the timestamps in eeg_data by interpolating the accelerometer data values.\n",
    "    #Stores the column names of accel_data as accel_data_columns for later use in the final DataFrame\n",
    "    #to ensure the returned DataFrame has the same structure as the original\n",
    "    accel_data_columns = accel_data.columns\n",
    "    #Converts accel_data to a 2D Numpy Array\n",
    "    #where rows correspond to timestamps and columns correspond to accelerometer measurements.\n",
    "    accel_data_np = accel_data.to_numpy()\n",
    "    #Creates an empty NumPy array to store the interpolated accelerometer data.\n",
    "    #The number of rows matches the number of rows in eeg_data (the number of EEG timestamps).\n",
    "    #The number of columns matches the number of columns in accel_data_np.\n",
    "    new_accel_data = np.zeros((len(eeg_data), accel_data_np.shape[1]))\n",
    "    for i in range(accel_data_np.shape[1]):\n",
    "        new_accel_data[:, i] = np.interp(\n",
    "            eeg_data[\"timestamp\"],\n",
    "            accel_data[\"timestamp\"],\n",
    "            accel_data_np[:, i],\n",
    "        )\n",
    "    #new_accel_data is transformed back into a DataFrame using the original column names\n",
    "    return pd.DataFrame(new_accel_data, columns=accel_data_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f35ecd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wiener Filter\n",
    "def wiener_filter(x, filter_type, mysize=None, noise=None):\n",
    "    num_epochs, num_channels, num_samples = x.shape\n",
    "    if filter_type == 1:\n",
    "        combined = x.reshape(-1)\n",
    "        filtered = signal.wiener(combined, mysize=mysize, noise=noise)\n",
    "        return filtered.reshape(x.shape)\n",
    "    elif filter_type == 2:\n",
    "        filtered = np.zeros_like(x)\n",
    "        for channel in range(num_channels):\n",
    "            combined = x[:, channel, :].reshape(-1)\n",
    "            filtered[:, channel, :] = signal.wiener(combined, mysize=mysize, noise=noise).reshape(\n",
    "                num_epochs, num_samples\n",
    "            )\n",
    "        return filtered\n",
    "    elif filter_type == 3:\n",
    "        filtered = np.zeros_like(x)\n",
    "        for epoch in range(num_epochs):\n",
    "            combined = x[epoch, :, :].reshape(-1)\n",
    "            filtered[epoch, :, :] = signal.wiener(combined, mysize=mysize, noise=noise).reshape(\n",
    "                num_channels, num_samples\n",
    "            )\n",
    "        return filtered\n",
    "    else:\n",
    "        filtered = np.copy(x)\n",
    "        for epoch in range(num_epochs):\n",
    "            for channel in range(num_channels):\n",
    "                filtered[epoch, channel] = signal.wiener(\n",
    "                    x[epoch, channel], mysize=mysize, noise=noise\n",
    "                )\n",
    "        return filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489cad11",
   "metadata": {},
   "source": [
    "Load Data from Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "623bc587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_directory(data_directory_path: str):\n",
    "    #Joins the directory path with the file names to create the full paths to the files.\n",
    "    eeg_file = os.path.join(data_directory_path, \"eeg_data_raw.csv\")\n",
    "    accel_file = os.path.join(data_directory_path, \"accelerometer_data.csv\")\n",
    "    action_file = os.path.join(data_directory_path, \"action_data.csv\")\n",
    "\n",
    "    if not all(map(os.path.exists, [eeg_file, accel_file, action_file])):\n",
    "        logger.warning(f\"Missing files in {data_directory_path}\")\n",
    "        return None, None, None\n",
    "\n",
    "    eeg_data = pd.read_csv(eeg_file)\n",
    "    accel_data = pd.read_csv(accel_file)\n",
    "    action_data = pd.read_csv(action_file)\n",
    "\n",
    "    print(f\"EEG Data Shape: {eeg_data.shape}\\n{eeg_data.head()}\")\n",
    "    print(f\"Accelerometer Data Shape: {accel_data.shape}\\n{accel_data.head()}\")\n",
    "    print(f\"Action Data Shape: {action_data.shape}\\n{action_data.head()}\")\n",
    "    \n",
    "    #return DataFrames\n",
    "    return eeg_data, accel_data, action_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a872e2d8",
   "metadata": {},
   "source": [
    "Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b218eb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(eeg_data, accel_data, action_data):\n",
    "    # Convert timestamps\n",
    "    eeg_data = convert_timestamp_to_time_since_last_epoch(eeg_data)\n",
    "    accel_data = convert_timestamp_to_time_since_last_epoch(accel_data)\n",
    "    action_data = convert_timestamp_to_time_since_last_epoch(action_data)\n",
    "\n",
    "    # Align timestamps\n",
    "    start_time = max(eeg_data[\"timestamp\"].min(), accel_data[\"timestamp\"].min())\n",
    "    end_time = min(eeg_data[\"timestamp\"].max(), accel_data[\"timestamp\"].max())\n",
    "    eeg_data = align_data_to_experiment_start_and_end_time(eeg_data, start_time, end_time)\n",
    "    accel_data = align_data_to_experiment_start_and_end_time(accel_data, start_time, end_time)\n",
    "\n",
    "    print(f\"Aligned EEG Data Shape: {eeg_data.shape}\")\n",
    "    print(f\"Aligned Accelerometer Data Shape: {accel_data.shape}\")\n",
    "    return eeg_data, accel_data, action_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb758440",
   "metadata": {},
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc33fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(x):\n",
    "    print(f\"Original Shape: {x.shape}\")\n",
    "    num_epochs, num_channels, num_samples = x.shape\n",
    "\n",
    "    # Perform PCA\n",
    "    x_reshaped = x.reshape(num_epochs * num_channels, -1)\n",
    "    pca = PCA(n_components=10)\n",
    "    features = pca.fit_transform(x_reshaped)\n",
    "    print(f\"PCA Features Shape: {features.shape}\")\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c5090d",
   "metadata": {},
   "source": [
    "Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "711027af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-03 11:16:09.345\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_data_from_directory\u001b[0m:\u001b[36m8\u001b[0m - \u001b[33m\u001b[1mMissing files in /Users/yuelei/Desktop/Universum-clean/DataCollection/data/105/1\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolved Data Directory: /Users/yuelei/Desktop/Universum-clean/DataCollection/data/105/1\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    actions = {\n",
    "        \"end_collection\": Action(action_value=5, text=\"End of Collection\", audio=None, image=None),\n",
    "    }\n",
    "\n",
    "    subject_id = 105\n",
    "    visit_number = 1\n",
    "    data_directory = os.path.abspath(f\"../DataCollection/data/{subject_id}/{visit_number}/\")\n",
    "    print(f\"Resolved Data Directory: {data_directory}\")\n",
    "    \n",
    "    eeg_data, accel_data, action_data = get_data_from_directory(data_directory)\n",
    "    if eeg_data is not None:\n",
    "        eeg_data, accel_data, action_data = preprocess_data(eeg_data, accel_data, action_data)\n",
    "\n",
    "        # Apply preprocessing\n",
    "        eeg_data_array = eeg_data.drop(columns=[\"timestamp\"]).to_numpy()\n",
    "        filtered_data = wiener_filter(eeg_data_array, filter_type=1)\n",
    "        print(f\"Filtered Data Shape: {filtered_data.shape}\")\n",
    "\n",
    "        # Feature extraction\n",
    "        features = feature_extract(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063bf70b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (neurotech_environment)",
   "language": "python",
   "name": "neurotech_environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
